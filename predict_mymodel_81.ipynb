{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56883630",
   "metadata": {},
   "source": [
    "# Итоговая модель прогнозирования stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde0a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym = 'SBERP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af5ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\n",
    "    \"figure.facecolor\"\n",
    "] = \"w\"  # force white background on plots when using dark mode in JupyterLab\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime, date, timedelta\n",
    "import time\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b14882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ca34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{sym}_day.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d03421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция по созданию сгенерированных признаков\n",
    "def make_features(data):\n",
    "    data['year'] = data.index.year\n",
    "    data['month'] = data.index.month\n",
    "    data['day'] = data.index.day\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    data['is_weekend'] = data.index.isin([5,6])*1\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c132f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e963e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding indicators\n",
    "data['RSI'] = ta.rsi(data.CLOSE, length=15)\n",
    "data['EMAF'] = ta.ema(data.CLOSE, length=20)\n",
    "data['EMAM'] = ta.ema(data.CLOSE, length=100)\n",
    "data['EMAS'] = ta.ema(data.CLOSE, length=150)\n",
    "data['VWAP'] = ta.vwap(data.HIGH, data.LOW, data.CLOSE, data.VOL, anchor = \"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f2c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Target'] = data['CLOSE'] - data.OPEN\n",
    "data['Target'] = data['Target'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcfc71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "data.drop(['VOL', 'TICKER', 'PER', 'TIME' ], axis=1, inplace=True)\n",
    "data_set = data.iloc[:, 0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce8130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range=(-1, 1))\n",
    "data_scaled = sc.fit_transform(data_set.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f06c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeriesDataset(Dataset):\n",
    "                            def __init__(self, data, window_size):\n",
    "                                    self.data = data  \n",
    "                                    self.window_size = window_size\n",
    "                    \n",
    "                                    self.y = []\n",
    "                                    self.sequence = []\n",
    "                                \n",
    "                                    for j in range(self.data.shape[1]):\n",
    "                                                    self.sequence.append([])\n",
    "                                                    self.y.append([])\n",
    "                                            \n",
    "                                                    for i in range(self.data.shape[0] - self.window_size):\n",
    "                                                            self.sequence[j].append(self.data[i : i + self.window_size, j])\n",
    "                                                            self.y[j].append(self.data[i + 1 : i + self.window_size + 1, j])\n",
    "                                  \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    self.sequence = np.array(np.moveaxis(self.sequence, [0], [2]))\n",
    "                                    self.y = np.array(np.moveaxis(self.y, [0], [2]))\n",
    "\n",
    "                                    \n",
    "\n",
    "                        \n",
    "                            def __len__(self):\n",
    "                                                return len(self.data) - self.window_size\n",
    "\n",
    "                            def __getitem__(self, idx):\n",
    "                                                sequence = self.sequence[idx]\n",
    "                                                label = self.y[idx]\n",
    "                                                pred = self.y[idx][-1, 3]\n",
    "                                                                                                                                         \n",
    "                                                sequence = torch.tensor(sequence).float()\n",
    "                                                label = torch.tensor(label).float()\n",
    "                                                pred = torch.tensor(pred).float()\n",
    "                     \n",
    "                                        \n",
    "                                                return sequence, label, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c545758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Model_GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, bidirectional=False, method='GRU', dropout_p = 0.2):\n",
    "        super(My_Model_GRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        self.hidden_var = hidden_size if bidirectional else hidden_size // 2\n",
    "        self.bidirectional = bidirectional\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.relu = nn.ReLU()\n",
    "        self.do = nn.Dropout(dropout_p)\n",
    "        self.method = method\n",
    "        if self.method == 'GRU':\n",
    "                self.net = nn.GRU(input_size=input_size, hidden_size=hidden_size,\n",
    "                                                num_layers=num_layers, batch_first=True, bidirectional=self.bidirectional)\n",
    "        elif self.method == 'LSTM':\n",
    "                self.net = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                                                num_layers=num_layers, batch_first=True, bidirectional=self.bidirectional)\n",
    "        self.linear1 = nn.Linear(self.hidden_size, self.hidden_var)\n",
    "        self.linear2 = nn.Linear(self.hidden_var, output_size)\n",
    "         \n",
    "        \n",
    "    def forward(self, input, future=0, y=None):\n",
    "\n",
    "        ht, ct = self.net(input)\n",
    "        output = self.linear1(self.do(ht))\n",
    "        output = self.relu(output)\n",
    "        outputs = self.linear2(output)\n",
    "        teacher = outputs\n",
    "        \n",
    "        if future != 0:\n",
    "            out = []\n",
    "            c = 0\n",
    "            for i in range(future):\n",
    "                if y is not None and random.random() > 0.5:\n",
    "                    c += 1\n",
    "                    outputs = y[:, [i], :]  # teacher forcing\n",
    "                ht, ct = self.net(outputs, ct)\n",
    "                output = self.linear1(self.do(ht))\n",
    "                output = self.relu(output)\n",
    "                output = self.linear2(output)\n",
    "                out += [output[:,-1,:]]\n",
    "            \n",
    "            out = torch.stack(out, 1).squeeze(2)\n",
    "            \n",
    "            if c > 0 : outputs = torch.cat((teacher, out), 1) \n",
    "            else: outputs = torch.cat((outputs, out), 1) \n",
    "      \n",
    "        return outputs, outputs[:,-1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdc9d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization:\n",
    "    \"\"\" A helper class to train, test and diagnose the GRU\"\"\"\n",
    "\n",
    "    def __init__(self, model, loss_fn, optimizer, scheduler):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.futures = []\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        dataloader_train,\n",
    "        n_epochs,\n",
    "        dataloader_val = None,\n",
    "        do_teacher_forcing=None,\n",
    "    \n",
    "    ):\n",
    "        for epoch in range(n_epochs):\n",
    "            start_time = time.time()\n",
    "            train_loss = 0\n",
    "#             loop = tqdm(dataloader_train, desc='Train', colour='green')\n",
    "            for b, batch in enumerate(dataloader_train):\n",
    "                x_batch, y_batch, y_b = batch[0], batch[1], batch[2]\n",
    "                y_pr, y_pred = self._predict(x_batch, y_batch, do_teacher_forcing)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.loss_fn(y_pr, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            self.scheduler.step()\n",
    "            train_loss /= (b+1)\n",
    "            self.train_losses.append(train_loss)\n",
    "\n",
    "            self._validation(dataloader_val)\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "#             print(\n",
    "#                 \"Epoch %d Train loss: %.2f. Validation loss: %.2f. Avg future: %.2f. Elapsed time: %.2fs.\"\n",
    "#                 % (epoch + 1, train_loss, self.val_losses[-1], np.average(self.futures), elapsed)\n",
    "#             )\n",
    "            \n",
    "#             torch.save(self.model.state_dict(), f'./chkpt_mymodel_{epoch+1}.pth')\n",
    "    \n",
    "    def _predict(self, x_batch, y_batch, do_teacher_forcing):\n",
    "        if do_teacher_forcing:\n",
    "            future = random.randint(1, int(y_batch.shape[1]) / 2)\n",
    "            limit = x_batch.size(1) - future\n",
    "            y_pr, y_pred = self.model(x_batch[:, :limit, :], future=future, y=y_batch[:, limit:, :])\n",
    "        else:\n",
    "            future = 0\n",
    "            y_pr, y_pred = self.model(x_batch)\n",
    "        self.futures.append(future)\n",
    "        return y_pr, y_pred\n",
    "    \n",
    "    def _validation(self, dataloader_val):\n",
    "        if dataloader_val is None:\n",
    "            return\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "#             loop = tqdm(dataloader_val, desc='Val', colour='green')\n",
    "            for b, batch in enumerate(dataloader_val):\n",
    "                x_batch, y_batch, y_b = batch[0], batch[1], batch[2]\n",
    "                y_pr, y_pred = self.model(x_batch)\n",
    "                loss = self.loss_fn(y_pr, y_batch)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= b+1\n",
    "            self.val_losses.append(val_loss)\n",
    "\n",
    "    def evaluate(self, dataloader_test, future=1):\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            actual, predicted = [], []\n",
    "#             loop = tqdm(dataloader_test, desc='Test', colour='green')\n",
    "            for b, batch in enumerate(dataloader_test):\n",
    "                x_batch, y_batch, y_b = batch[0], batch[1], batch[2]\n",
    "                y_pr, y_pred = self.model(x_batch, future=future)\n",
    "                y_pr = (\n",
    "                    y_pr[:, -y_batch.shape[1] :, :] if y_pr.shape[1] > y_batch.shape[1] else y_pr\n",
    "                )\n",
    "                loss = self.loss_fn(y_pr, y_batch)\n",
    "                test_loss += loss.item()            \n",
    "                if x_batch.shape[0] > 1:\n",
    "                            actual += torch.squeeze(y_batch[:, -1, :]).data.cpu().numpy().tolist()\n",
    "\n",
    "                            predicted += torch.squeeze(y_pr[:, -1, :]).data.cpu().numpy().tolist()\n",
    "\n",
    "                else:\n",
    "                            actual.append(torch.squeeze(y_batch[:, -1, :]).data.cpu().numpy().tolist())\n",
    "                            predicted.append(torch.squeeze(y_pr[:, -1, :]).data.cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "            \n",
    "            test_loss /= (b+1)\n",
    "            return actual, predicted, test_loss\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label=\"Training loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4e5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(scalar, actual, predicted, columns, future = 0):\n",
    "    y = pd.DataFrame(scalar.inverse_transform(np.array(actual)), columns = columns)\n",
    "    y_pred = pd.DataFrame(scalar.inverse_transform(np.array(predicted)), columns = columns)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    \n",
    "    y['Target'] = y['CLOSE'] - y.OPEN\n",
    "    y['TargetClass'] = [1 if y.Target[i] > 0 else 0 for i in range(len(y))]\n",
    "    \n",
    "    y_pred['Target'] = y_pred['CLOSE'] - y_pred['CLOSE'].shift()\n",
    "    y_pred['TargetClass'] = [1 if y_pred.Target[i] > 0 else 0 for i in range(len(y_pred))]\n",
    "    \n",
    "    if future == 0:\n",
    "                   f1 = metrics.f1_score(y['TargetClass'], y_pred['TargetClass'])\n",
    "                   acc = metrics.accuracy_score(y['TargetClass'], y_pred['TargetClass'])\n",
    "                   recall = metrics.precision_score(y['TargetClass'], y_pred['TargetClass'])\n",
    "    else: \n",
    "                   f1 = metrics.f1_score(y_pred['TargetClass'][future: ], y_pred['TargetClass'][:- future])\n",
    "                   acc = metrics.accuracy_score(y_pred['TargetClass'][future: ], y_pred['TargetClass'][:- future])\n",
    "                   recall = metrics.precision_score(y_pred['TargetClass'][future: ], y_pred['TargetClass'][:- future])\n",
    "            \n",
    "    \n",
    "    error = {'MSE': mse,'RMSE': rmse,'MAE': mae, 'f1': f1, 'acc': acc, 'recall': recall}\n",
    "#     print('MSE: {:.4f}, RMSE: {:.4f}, MAE: {:.4f}, f1: {:.4f}, acc: {:.4f}, recall: {:.4f}'.format(mse, rmse, mae, f1, acc, recall))\n",
    "    \n",
    "    return y, y_pred, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57807148",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 12\n",
    "output_size = 12\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b978ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = [20, 30, 40, 50, 60, 70, 80, 90]\n",
    "HIDDEN = [32, 64, 128, 256]\n",
    "NUM = [1, 2]\n",
    "met = ['GRU', 'LSTM']\n",
    "bid = [True, False]\n",
    "teach = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc248b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8/8 [26:43:32<00:00, 12026.61s/it]\n"
     ]
    }
   ],
   "source": [
    "model = []\n",
    "score = []\n",
    "\n",
    "for WINDOW_SIZE in tqdm(W):\n",
    "    \n",
    "    dataset = SeriesDataset(data_scaled, WINDOW_SIZE)\n",
    "\n",
    "    splitlimit1 = int(len(dataset) * 0.8)\n",
    "    train_dataset =  Subset(dataset, np.arange(splitlimit1))\n",
    "    t_dataset =  Subset(dataset, np.arange(splitlimit1, len(dataset)))\n",
    "    splitlimit2 = int(len(t_dataset) * 0.5)\n",
    "    val_dataset =  Subset(t_dataset, np.arange(splitlimit2))\n",
    "    test_dataset =  Subset(t_dataset, np.arange(splitlimit2, len(t_dataset)))\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "    train_dataloader1 = DataLoader(train_dataset, batch_size = 1)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size = 1)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size = 1)\n",
    "\n",
    "    for HIDDEN_SIZE in HIDDEN:\n",
    "                    for NUM_L in NUM:\n",
    "                              for method in met:\n",
    "                                         for bidirectional in bid:\n",
    "                                                           for teacher in teach:\n",
    "                                        \n",
    "                                                                        model_my = My_Model_GRU(input_size, HIDDEN_SIZE, NUM_L, output_size, bidirectional=bidirectional, method = method)\n",
    "                                                                        criterion = nn.MSELoss()\n",
    "                                                                        optimizer = optim.Adam(model_my.parameters(), lr=0.01)\n",
    "                                                                        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "              \n",
    "                                                                        optimization_1 = Optimization(model_my, criterion, optimizer, scheduler)\n",
    "                                                                        optimization_1.train(train_dataloader, n_epochs = EPOCHS, dataloader_val = val_dataloader, do_teacher_forcing=teacher)\n",
    "\n",
    "                                                                        actual_1, predicted_1, test_loss_1 = optimization_1.evaluate(test_dataloader, future = 0)\n",
    "                                                                        df_actual_1, df_predicted_1, error1 = to_dataframe(sc, actual_1, predicted_1, data_set.columns[1:], future = 0) \n",
    "                                                                        error1['Loss'] = test_loss_1\n",
    "                                \n",
    "                                                                        m1 = f'TEST_W{WINDOW_SIZE}_H{HIDDEN_SIZE}_N{NUM_L}_m{method}_b{bidirectional}_t{teacher}'\n",
    "                                                                        model.append(m1)\n",
    "                                                                        score.append(error1)\n",
    "                                                                        \n",
    "                                                                        actual_2, predicted_2, val_loss_2 = optimization_1.evaluate(val_dataloader, future=0)\n",
    "                                                                        df_actual_2, df_predicted_2, error2 = to_dataframe(sc, actual_2, predicted_2, data_set.columns[1:]) \n",
    "                                                                        error2['Loss'] = val_loss_2\n",
    "                                                            \n",
    "                                                                        m2 = f'VAL_W{WINDOW_SIZE}_H{HIDDEN_SIZE}_N{NUM_L}_m{method}_b{bidirectional}_t{teacher}'                                               \n",
    "                                                                        model.append(m2)\n",
    "                                                                        score.append(error2)\n",
    "\n",
    "                                                                        actual_3, predicted_3, train_loss_3 = optimization_1.evaluate(train_dataloader1, future=0)\n",
    "                                                                        df_actual_3, df_predicted_3, error3 = to_dataframe(sc, actual_3, predicted_3, data_set.columns[1:])\n",
    "                                                                        error3['Loss'] = train_loss_3\n",
    "                                                                        \n",
    "                                                                        m3 = f'TRAIN_W{WINDOW_SIZE}_H{HIDDEN_SIZE}_N{NUM_L}_m{method}_b{bidirectional}_t{teacher}'\n",
    "                                                                        model.append(m3)\n",
    "                                                                        score.append(error3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b70fcb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "      <th>recall</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TEST_W20_H32_N1_mGRU_bTrue_tTrue</th>\n",
       "      <td>106.420547</td>\n",
       "      <td>10.316034</td>\n",
       "      <td>6.636041</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.045912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL_W20_H32_N1_mGRU_bTrue_tTrue</th>\n",
       "      <td>332.737538</td>\n",
       "      <td>18.241095</td>\n",
       "      <td>11.811974</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.403101</td>\n",
       "      <td>0.057502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_W20_H32_N1_mGRU_bTrue_tTrue</th>\n",
       "      <td>60.967827</td>\n",
       "      <td>7.808190</td>\n",
       "      <td>4.870432</td>\n",
       "      <td>0.499263</td>\n",
       "      <td>0.501468</td>\n",
       "      <td>0.504469</td>\n",
       "      <td>0.014806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_W20_H32_N1_mGRU_bTrue_tFalse</th>\n",
       "      <td>148.379624</td>\n",
       "      <td>12.181118</td>\n",
       "      <td>7.841569</td>\n",
       "      <td>0.513208</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.519084</td>\n",
       "      <td>0.049455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL_W20_H32_N1_mGRU_bTrue_tFalse</th>\n",
       "      <td>374.524003</td>\n",
       "      <td>19.352623</td>\n",
       "      <td>12.781358</td>\n",
       "      <td>0.419214</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.054020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL_W90_H256_N2_mLSTM_bFalse_tTrue</th>\n",
       "      <td>483.215512</td>\n",
       "      <td>21.982164</td>\n",
       "      <td>14.585394</td>\n",
       "      <td>0.431535</td>\n",
       "      <td>0.449799</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.084486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_W90_H256_N2_mLSTM_bFalse_tTrue</th>\n",
       "      <td>58.466068</td>\n",
       "      <td>7.646311</td>\n",
       "      <td>4.924428</td>\n",
       "      <td>0.534917</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507207</td>\n",
       "      <td>0.033973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_W90_H256_N2_mLSTM_bFalse_tFalse</th>\n",
       "      <td>109.780507</td>\n",
       "      <td>10.477619</td>\n",
       "      <td>6.726227</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.510040</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.072474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL_W90_H256_N2_mLSTM_bFalse_tFalse</th>\n",
       "      <td>355.712152</td>\n",
       "      <td>18.860333</td>\n",
       "      <td>12.551012</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.449799</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.065268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_W90_H256_N2_mLSTM_bFalse_tFalse</th>\n",
       "      <td>32.145074</td>\n",
       "      <td>5.669663</td>\n",
       "      <td>3.619897</td>\n",
       "      <td>0.501756</td>\n",
       "      <td>0.500503</td>\n",
       "      <td>0.501002</td>\n",
       "      <td>0.020481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1536 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              MSE       RMSE        MAE  \\\n",
       "TEST_W20_H32_N1_mGRU_bTrue_tTrue       106.420547  10.316034   6.636041   \n",
       "VAL_W20_H32_N1_mGRU_bTrue_tTrue        332.737538  18.241095  11.811974   \n",
       "TRAIN_W20_H32_N1_mGRU_bTrue_tTrue       60.967827   7.808190   4.870432   \n",
       "TEST_W20_H32_N1_mGRU_bTrue_tFalse      148.379624  12.181118   7.841569   \n",
       "VAL_W20_H32_N1_mGRU_bTrue_tFalse       374.524003  19.352623  12.781358   \n",
       "...                                           ...        ...        ...   \n",
       "VAL_W90_H256_N2_mLSTM_bFalse_tTrue     483.215512  21.982164  14.585394   \n",
       "TRAIN_W90_H256_N2_mLSTM_bFalse_tTrue    58.466068   7.646311   4.924428   \n",
       "TEST_W90_H256_N2_mLSTM_bFalse_tFalse   109.780507  10.477619   6.726227   \n",
       "VAL_W90_H256_N2_mLSTM_bFalse_tFalse    355.712152  18.860333  12.551012   \n",
       "TRAIN_W90_H256_N2_mLSTM_bFalse_tFalse   32.145074   5.669663   3.619897   \n",
       "\n",
       "                                             f1       acc    recall      Loss  \n",
       "TEST_W20_H32_N1_mGRU_bTrue_tTrue       0.492537  0.468750  0.492537  0.045912  \n",
       "VAL_W20_H32_N1_mGRU_bTrue_tTrue        0.426230  0.453125  0.403101  0.057502  \n",
       "TRAIN_W20_H32_N1_mGRU_bTrue_tTrue      0.499263  0.501468  0.504469  0.014806  \n",
       "TEST_W20_H32_N1_mGRU_bTrue_tFalse      0.513208  0.496094  0.519084  0.049455  \n",
       "VAL_W20_H32_N1_mGRU_bTrue_tFalse       0.419214  0.480469  0.421053  0.054020  \n",
       "...                                         ...       ...       ...       ...  \n",
       "VAL_W90_H256_N2_mLSTM_bFalse_tTrue     0.431535  0.449799  0.409449  0.084486  \n",
       "TRAIN_W90_H256_N2_mLSTM_bFalse_tTrue   0.534917  0.507545  0.507207  0.033973  \n",
       "TEST_W90_H256_N2_mLSTM_bFalse_tFalse   0.534351  0.510040  0.534351  0.072474  \n",
       "VAL_W90_H256_N2_mLSTM_bFalse_tFalse    0.396476  0.449799  0.398230  0.065268  \n",
       "TRAIN_W90_H256_N2_mLSTM_bFalse_tFalse  0.501756  0.500503  0.501002  0.020481  \n",
       "\n",
       "[1536 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = pd.DataFrame(score , index = model)\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20c1cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_excel('Pipeline_model.xlsx', index = True)\n",
    "df_model.to_csv('Pipeline_model.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1909b3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "      <th>recall</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.536000e+03</td>\n",
       "      <td>1536.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "      <td>1536.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.847539e+04</td>\n",
       "      <td>26.775233</td>\n",
       "      <td>17.570795</td>\n",
       "      <td>0.488402</td>\n",
       "      <td>0.493629</td>\n",
       "      <td>0.485487</td>\n",
       "      <td>1.831810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.861123e+05</td>\n",
       "      <td>166.663001</td>\n",
       "      <td>111.831215</td>\n",
       "      <td>0.039603</td>\n",
       "      <td>0.027753</td>\n",
       "      <td>0.043633</td>\n",
       "      <td>22.744952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.834096e+01</td>\n",
       "      <td>4.282635</td>\n",
       "      <td>2.705921</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.376984</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.002762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.928534e+01</td>\n",
       "      <td>8.323782</td>\n",
       "      <td>5.272333</td>\n",
       "      <td>0.466601</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.458568</td>\n",
       "      <td>0.022521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.343430e+02</td>\n",
       "      <td>11.590623</td>\n",
       "      <td>7.517030</td>\n",
       "      <td>0.494289</td>\n",
       "      <td>0.494489</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.047885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.224755e+02</td>\n",
       "      <td>17.957603</td>\n",
       "      <td>11.818898</td>\n",
       "      <td>0.511124</td>\n",
       "      <td>0.509785</td>\n",
       "      <td>0.510922</td>\n",
       "      <td>0.074661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.328876e+07</td>\n",
       "      <td>3645.375486</td>\n",
       "      <td>2514.837464</td>\n",
       "      <td>0.630037</td>\n",
       "      <td>0.600791</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>397.920060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MSE         RMSE          MAE           f1          acc  \\\n",
       "count  1.536000e+03  1536.000000  1536.000000  1536.000000  1536.000000   \n",
       "mean   2.847539e+04    26.775233    17.570795     0.488402     0.493629   \n",
       "std    4.861123e+05   166.663001   111.831215     0.039603     0.027753   \n",
       "min    1.834096e+01     4.282635     2.705921     0.333333     0.376984   \n",
       "25%    6.928534e+01     8.323782     5.272333     0.466601     0.478431   \n",
       "50%    1.343430e+02    11.590623     7.517030     0.494289     0.494489   \n",
       "75%    3.224755e+02    17.957603    11.818898     0.511124     0.509785   \n",
       "max    1.328876e+07  3645.375486  2514.837464     0.630037     0.600791   \n",
       "\n",
       "            recall         Loss  \n",
       "count  1536.000000  1536.000000  \n",
       "mean      0.485487     1.831810  \n",
       "std       0.043633    22.744952  \n",
       "min       0.333333     0.002762  \n",
       "25%       0.458568     0.022521  \n",
       "50%       0.492188     0.047885  \n",
       "75%       0.510922     0.074661  \n",
       "max       0.614286   397.920060  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm = pd.read_csv('Pipeline_model.csv', index_col=0)\n",
    "dfm.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a2a5dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "      <th>recall</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TEST_W20_H32_N1_mGRU_bTrue_tTrue</th>\n",
       "      <td>106.420547</td>\n",
       "      <td>10.316034</td>\n",
       "      <td>6.636041</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.045912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL_W20_H32_N1_mGRU_bTrue_tTrue</th>\n",
       "      <td>332.737538</td>\n",
       "      <td>18.241095</td>\n",
       "      <td>11.811974</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.403101</td>\n",
       "      <td>0.057502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_W20_H32_N1_mGRU_bTrue_tTrue</th>\n",
       "      <td>60.967827</td>\n",
       "      <td>7.808190</td>\n",
       "      <td>4.870432</td>\n",
       "      <td>0.499263</td>\n",
       "      <td>0.501468</td>\n",
       "      <td>0.504469</td>\n",
       "      <td>0.014806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_W20_H32_N1_mGRU_bTrue_tFalse</th>\n",
       "      <td>148.379624</td>\n",
       "      <td>12.181118</td>\n",
       "      <td>7.841569</td>\n",
       "      <td>0.513208</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.519084</td>\n",
       "      <td>0.049455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL_W20_H32_N1_mGRU_bTrue_tFalse</th>\n",
       "      <td>374.524003</td>\n",
       "      <td>19.352623</td>\n",
       "      <td>12.781358</td>\n",
       "      <td>0.419214</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.054020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL_W90_H256_N2_mLSTM_bFalse_tTrue</th>\n",
       "      <td>483.215512</td>\n",
       "      <td>21.982164</td>\n",
       "      <td>14.585394</td>\n",
       "      <td>0.431535</td>\n",
       "      <td>0.449799</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.084486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_W90_H256_N2_mLSTM_bFalse_tTrue</th>\n",
       "      <td>58.466068</td>\n",
       "      <td>7.646311</td>\n",
       "      <td>4.924428</td>\n",
       "      <td>0.534917</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507207</td>\n",
       "      <td>0.033973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_W90_H256_N2_mLSTM_bFalse_tFalse</th>\n",
       "      <td>109.780507</td>\n",
       "      <td>10.477619</td>\n",
       "      <td>6.726227</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.510040</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.072474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL_W90_H256_N2_mLSTM_bFalse_tFalse</th>\n",
       "      <td>355.712152</td>\n",
       "      <td>18.860333</td>\n",
       "      <td>12.551012</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.449799</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.065268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_W90_H256_N2_mLSTM_bFalse_tFalse</th>\n",
       "      <td>32.145074</td>\n",
       "      <td>5.669663</td>\n",
       "      <td>3.619897</td>\n",
       "      <td>0.501756</td>\n",
       "      <td>0.500503</td>\n",
       "      <td>0.501002</td>\n",
       "      <td>0.020481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1536 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              MSE       RMSE        MAE  \\\n",
       "TEST_W20_H32_N1_mGRU_bTrue_tTrue       106.420547  10.316034   6.636041   \n",
       "VAL_W20_H32_N1_mGRU_bTrue_tTrue        332.737538  18.241095  11.811974   \n",
       "TRAIN_W20_H32_N1_mGRU_bTrue_tTrue       60.967827   7.808190   4.870432   \n",
       "TEST_W20_H32_N1_mGRU_bTrue_tFalse      148.379624  12.181118   7.841569   \n",
       "VAL_W20_H32_N1_mGRU_bTrue_tFalse       374.524003  19.352623  12.781358   \n",
       "...                                           ...        ...        ...   \n",
       "VAL_W90_H256_N2_mLSTM_bFalse_tTrue     483.215512  21.982164  14.585394   \n",
       "TRAIN_W90_H256_N2_mLSTM_bFalse_tTrue    58.466068   7.646311   4.924428   \n",
       "TEST_W90_H256_N2_mLSTM_bFalse_tFalse   109.780507  10.477619   6.726227   \n",
       "VAL_W90_H256_N2_mLSTM_bFalse_tFalse    355.712152  18.860333  12.551012   \n",
       "TRAIN_W90_H256_N2_mLSTM_bFalse_tFalse   32.145074   5.669663   3.619897   \n",
       "\n",
       "                                             f1       acc    recall      Loss  \n",
       "TEST_W20_H32_N1_mGRU_bTrue_tTrue       0.492537  0.468750  0.492537  0.045912  \n",
       "VAL_W20_H32_N1_mGRU_bTrue_tTrue        0.426230  0.453125  0.403101  0.057502  \n",
       "TRAIN_W20_H32_N1_mGRU_bTrue_tTrue      0.499263  0.501468  0.504469  0.014806  \n",
       "TEST_W20_H32_N1_mGRU_bTrue_tFalse      0.513208  0.496094  0.519084  0.049455  \n",
       "VAL_W20_H32_N1_mGRU_bTrue_tFalse       0.419214  0.480469  0.421053  0.054020  \n",
       "...                                         ...       ...       ...       ...  \n",
       "VAL_W90_H256_N2_mLSTM_bFalse_tTrue     0.431535  0.449799  0.409449  0.084486  \n",
       "TRAIN_W90_H256_N2_mLSTM_bFalse_tTrue   0.534917  0.507545  0.507207  0.033973  \n",
       "TEST_W90_H256_N2_mLSTM_bFalse_tFalse   0.534351  0.510040  0.534351  0.072474  \n",
       "VAL_W90_H256_N2_mLSTM_bFalse_tFalse    0.396476  0.449799  0.398230  0.065268  \n",
       "TRAIN_W90_H256_N2_mLSTM_bFalse_tFalse  0.501756  0.500503  0.501002  0.020481  \n",
       "\n",
       "[1536 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d6d89e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "      <th>recall</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN_W90_H256_N1_mLSTM_bTrue_tFalse</th>\n",
       "      <td>22.808919</td>\n",
       "      <td>4.775868</td>\n",
       "      <td>3.185392</td>\n",
       "      <td>0.522805</td>\n",
       "      <td>0.510563</td>\n",
       "      <td>0.510536</td>\n",
       "      <td>0.002762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_W50_H256_N1_mLSTM_bFalse_tTrue</th>\n",
       "      <td>125.247845</td>\n",
       "      <td>11.191418</td>\n",
       "      <td>7.396815</td>\n",
       "      <td>0.630037</td>\n",
       "      <td>0.600791</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.070256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_W30_H256_N1_mGRU_bTrue_tTrue</th>\n",
       "      <td>18.340961</td>\n",
       "      <td>4.282635</td>\n",
       "      <td>2.705921</td>\n",
       "      <td>0.497093</td>\n",
       "      <td>0.490177</td>\n",
       "      <td>0.493269</td>\n",
       "      <td>0.004870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             MSE       RMSE       MAE  \\\n",
       "TRAIN_W90_H256_N1_mLSTM_bTrue_tFalse   22.808919   4.775868  3.185392   \n",
       "TEST_W50_H256_N1_mLSTM_bFalse_tTrue   125.247845  11.191418  7.396815   \n",
       "TRAIN_W30_H256_N1_mGRU_bTrue_tTrue     18.340961   4.282635  2.705921   \n",
       "\n",
       "                                            f1       acc    recall      Loss  \n",
       "TRAIN_W90_H256_N1_mLSTM_bTrue_tFalse  0.522805  0.510563  0.510536  0.002762  \n",
       "TEST_W50_H256_N1_mLSTM_bFalse_tTrue   0.630037  0.600791  0.614286  0.070256  \n",
       "TRAIN_W30_H256_N1_mGRU_bTrue_tTrue    0.497093  0.490177  0.493269  0.004870  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfb = []\n",
    "dfb.append(dfm[dfm.Loss == dfm.Loss.min()])\n",
    "dfb.append(dfm[dfm.recall == dfm.recall.max()])\n",
    "dfb.append(dfm[dfm.acc == dfm.acc.max()])\n",
    "dfb.append(dfm[dfm.f1 == dfm.f1.max()])\n",
    "dfb.append(dfm[dfm.MAE == dfm.MAE.min()])\n",
    "dfb.append(dfm[dfm.RMSE == dfm.RMSE.min()])\n",
    "dfb.append(dfm[dfm.MSE == dfm.MSE.min()])\n",
    "resul = pd.concat(dfb)\n",
    "resul = resul[~resul.index.duplicated(keep='first')]\n",
    "resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c368fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
